{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Eitan Spivak\n",
        "311391866\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HfA7caxv3Nsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ Install and Import Packages"
      ],
      "metadata": {
        "id": "zB-Sj6_fw18j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gRUj1RwwPOi"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages (only for Colab/first run)\n",
        "!pip install --upgrade --force-reinstall torchmetrics[image] torch-fidelity scikit-image\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2️⃣ Set Up Paths and Mount Drive"
      ],
      "metadata": {
        "id": "IBlGb6qDw3-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive (if using Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define data/model/result directories\n",
        "BASE_DIR = \"/content/drive/MyDrive/super_resolution\"\n",
        "TRAIN_HR = os.path.join(BASE_DIR, \"DIV2K_train_HR_cropped\")\n",
        "TRAIN_LR = os.path.join(BASE_DIR, \"DIV2K_train_LR_bicubic_X4\")\n",
        "VALID_HR = os.path.join(BASE_DIR, \"DIV2K_valid_HR_cropped\")\n",
        "VALID_LR = os.path.join(BASE_DIR, \"DIV2K_valid_LR_bicubic_X4\")\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "9lsEkMyxwb8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3️⃣ Dataset and DataLoader"
      ],
      "metadata": {
        "id": "kVKTJlNJw40c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PairedImageDataset(Dataset):\n",
        "    def __init__(self, lr_dir, hr_dir, transform=None):\n",
        "        self.lr_dir = lr_dir\n",
        "        self.hr_dir = hr_dir\n",
        "        self.filenames = sorted([f for f in os.listdir(lr_dir) if f.endswith('.png')])\n",
        "        self.transform = transform or transforms.ToTensor()\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.filenames[idx]\n",
        "        lr = Image.open(os.path.join(self.lr_dir, fname)).convert('RGB')\n",
        "        hr = Image.open(os.path.join(self.hr_dir, fname)).convert('RGB')\n",
        "        lr_up = lr.resize(hr.size, Image.BICUBIC)\n",
        "        return self.transform(lr), self.transform(lr_up), self.transform(hr)\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "train_dataset = PairedImageDataset(TRAIN_LR, TRAIN_HR)\n",
        "valid_dataset = PairedImageDataset(VALID_LR, VALID_HR)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "T7aIxCOOwb6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4️⃣ Model Definitions: SRCNN and ImprovedSRCNN"
      ],
      "metadata": {
        "id": "TWu7TLlAw5c5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SRCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 9, padding=4)\n",
        "        self.conv2 = nn.Conv2d(64, 32, 5, padding=2)\n",
        "        self.conv3 = nn.Conv2d(32, 3, 5, padding=2)\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        return self.conv3(x)\n",
        "\n",
        "class ImprovedSRCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.upsample = nn.Upsample(scale_factor=4, mode='bicubic', align_corners=False)\n",
        "        self.body = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 9, padding=4), nn.PReLU(),\n",
        "            nn.Conv2d(64, 64, 5, padding=2), nn.PReLU(),\n",
        "            nn.Conv2d(64, 32, 5, padding=2), nn.PReLU(),\n",
        "            nn.Conv2d(32, 16, 3, padding=1), nn.PReLU(),\n",
        "            nn.Conv2d(16, 3, 3, padding=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.upsample(x)\n",
        "        return x + self.body(x)\n"
      ],
      "metadata": {
        "id": "e3-VgIU8wb34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5️⃣ Training Functions"
      ],
      "metadata": {
        "id": "V5ALYUjnw6CU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_psnr(mse):\n",
        "    return 10 * np.log10(1.0 / mse) if mse > 0 else 100\n",
        "\n",
        "def train_model(model, train_loader, valid_loader, save_path, epochs=5, lr=1e-4, device='cuda', vanilla=True):\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    train_losses, valid_psnrs = [], []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for lr_img, lr_up_img, hr_img in train_loader:\n",
        "            inp = lr_up_img if vanilla else lr_img\n",
        "            inp, hr_img = inp.to(device), hr_img.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            sr = model(inp)\n",
        "            loss = criterion(sr, hr_img)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_psnr = 0.0\n",
        "        with torch.no_grad():\n",
        "            for lr_img, lr_up_img, hr_img in valid_loader:\n",
        "                inp = lr_up_img if vanilla else lr_img\n",
        "                inp, hr_img = inp.to(device), hr_img.to(device)\n",
        "                sr = model(inp)\n",
        "                mse = ((sr - hr_img) ** 2).mean().item()\n",
        "                val_psnr += calculate_psnr(mse)\n",
        "        val_psnr /= len(valid_loader)\n",
        "        valid_psnrs.append(val_psnr)\n",
        "        print(f\"[{'Vanilla' if vanilla else 'Improved'}] Epoch {epoch+1}: Loss={avg_loss:.6f}, Val PSNR={val_psnr:.2f}\")\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.legend()\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(valid_psnrs, label='Val PSNR')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return train_losses, valid_psnrs\n"
      ],
      "metadata": {
        "id": "8u1WKtnkwb1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6️⃣ Train or Load Models"
      ],
      "metadata": {
        "id": "SdGf29pIw697"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "vanilla_model = SRCNN()\n",
        "improved_model = ImprovedSRCNN()\n",
        "vanilla_path = os.path.join(MODEL_DIR, \"vanilla_srcnn.pth\")\n",
        "improved_path = os.path.join(MODEL_DIR, \"improved_srcnn.pth\")\n",
        "\n",
        "if os.path.exists(vanilla_path):\n",
        "    print(\"Loading Vanilla SRCNN weights...\")\n",
        "    vanilla_model.load_state_dict(torch.load(vanilla_path, map_location=device))\n",
        "else:\n",
        "    train_model(vanilla_model, train_loader, valid_loader, vanilla_path, epochs=5, lr=1e-4, device=device, vanilla=True)\n",
        "\n",
        "if os.path.exists(improved_path):\n",
        "    print(\"Loading Improved SRCNN weights...\")\n",
        "    improved_model.load_state_dict(torch.load(improved_path, map_location=device))\n",
        "else:\n",
        "    train_model(improved_model, train_loader, valid_loader, improved_path, epochs=5, lr=1e-4, device=device, vanilla=False)\n"
      ],
      "metadata": {
        "id": "lnxOuQZDwbzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7️⃣ Evaluation: Quantitative and Qualitative"
      ],
      "metadata": {
        "id": "Hq12ypfnw7fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "\n",
        "def evaluate_model(model, dataloader, device='cuda', vanilla=True):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    psnrs, ssims = [], []\n",
        "    fid = FrechetInceptionDistance(feature=2048, normalize=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        for lr, lr_up, hr in dataloader:\n",
        "            inp = lr_up if vanilla else lr\n",
        "            inp, hr = inp.to(device), hr.to(device)\n",
        "            sr = model(inp)\n",
        "            sr_np = np.clip(sr[0].cpu().permute(1,2,0).numpy(), 0, 1)\n",
        "            hr_np = np.clip(hr[0].cpu().permute(1,2,0).numpy(), 0, 1)\n",
        "            psnrs.append(compare_psnr(hr_np, sr_np, data_range=1.0))\n",
        "            ssims.append(compare_ssim(hr_np, sr_np, channel_axis=2, data_range=1.0))\n",
        "            fid.update(torch.clamp(sr, 0, 1), real=False)\n",
        "            fid.update(torch.clamp(hr, 0, 1), real=True)\n",
        "    print(f\"Avg PSNR: {np.mean(psnrs):.2f} ± {np.std(psnrs):.2f}\")\n",
        "    print(f\"Avg SSIM: {np.mean(ssims):.4f} ± {np.std(ssims):.4f}\")\n",
        "    print(f\"FID: {fid.compute().item():.4f}\")\n",
        "\n",
        "# Evaluate both models on validation set\n",
        "evaluate_model(vanilla_model, valid_loader, device=device, vanilla=True)\n",
        "evaluate_model(improved_model, valid_loader, device=device, vanilla=False)\n"
      ],
      "metadata": {
        "id": "mqTN18Pcwbw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8️⃣ Visualize Best/Worst Examples"
      ],
      "metadata": {
        "id": "R-tRDWwLw8EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_examples(model, dataloader, device='cuda', vanilla=True, num_examples=2):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    results = []\n",
        "    psnrs = []\n",
        "    with torch.no_grad():\n",
        "        for lr, lr_up, hr in dataloader:\n",
        "            inp = lr_up if vanilla else lr\n",
        "            inp, hr = inp.to(device), hr.to(device)\n",
        "            sr = model(inp)\n",
        "            sr_np = np.clip(sr[0].cpu().permute(1,2,0).numpy(), 0, 1)\n",
        "            hr_np = np.clip(hr[0].cpu().permute(1,2,0).numpy(), 0, 1)\n",
        "            lr_np = np.clip(lr[0].cpu().permute(1,2,0).numpy(), 0, 1)\n",
        "            psnr = compare_psnr(hr_np, sr_np, data_range=1.0)\n",
        "            psnrs.append(psnr)\n",
        "            results.append((lr_np, sr_np, hr_np, psnr))\n",
        "    best_indices = np.argsort(psnrs)[-num_examples:]\n",
        "    worst_indices = np.argsort(psnrs)[:num_examples]\n",
        "    for idx in np.concatenate([best_indices, worst_indices]):\n",
        "        lr_img, sr_img, hr_img, psnr = results[idx]\n",
        "        plt.figure(figsize=(15, 5))\n",
        "        plt.subplot(1, 3, 1); plt.imshow(lr_img); plt.title(\"LR Input\"); plt.axis('off')\n",
        "        plt.subplot(1, 3, 2); plt.imshow(sr_img); plt.title(f\"SR Output\\nPSNR={psnr:.2f}\"); plt.axis('off')\n",
        "        plt.subplot(1, 3, 3); plt.imshow(hr_img); plt.title(\"HR Ground Truth\"); plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "TiB7vu4Wwbum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9️⃣ Ablation Study: Weight Decay Example"
      ],
      "metadata": {
        "id": "xV9p84cSw8wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse train_model, just add a weight_decay parameter\n",
        "def train_model_with_reg(model, train_loader, valid_loader, save_path, epochs=5, lr=1e-4, device='cuda', weight_decay=0, vanilla=False):\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.MSELoss()\n",
        "    train_losses, valid_psnrs = [], []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for lr_img, lr_up_img, hr_img in train_loader:\n",
        "            inp = lr_up_img if vanilla else lr_img\n",
        "            inp, hr_img = inp.to(device), hr_img.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            sr = model(inp)\n",
        "            loss = criterion(sr, hr_img)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "        model.eval()\n",
        "        val_psnr = 0.0\n",
        "        with torch.no_grad():\n",
        "            for lr_img, lr_up_img, hr_img in valid_loader:\n",
        "                inp = lr_up_img if vanilla else lr_img\n",
        "                inp, hr_img = inp.to(device), hr_img.to(device)\n",
        "                sr = model(inp)\n",
        "                mse = ((sr - hr_img) ** 2).mean().item()\n",
        "                val_psnr += calculate_psnr(mse)\n",
        "        val_psnr /= len(valid_loader)\n",
        "        valid_psnrs.append(val_psnr)\n",
        "        print(f\"[{'Vanilla' if vanilla else 'Improved'} | WD={weight_decay}] Epoch {epoch+1}: Loss={avg_loss:.6f}, Val PSNR={val_psnr:.2f}\")\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    return train_losses, valid_psnrs\n",
        "\n",
        "# Train and plot both with and without regularization as needed for your ablation study\n"
      ],
      "metadata": {
        "id": "RS-dLCYNwbse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CHnzvGeSwbp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CH9QwNT5wbnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mvrSUdPtwblX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gsNs9MT_wbiM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}